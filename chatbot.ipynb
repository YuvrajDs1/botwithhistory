{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73a2833",
   "metadata": {},
   "source": [
    "### Chatbot with Conversational History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dceb6137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key=os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "585fb6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000014A040D6660>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000014A040D7230>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model='Gemma2-9b-It', groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a304336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Yuvraj, and you are a GenAI engineer!  \\n\\nIs there anything else you'd like to know about yourself or discuss? üòä  I'm here to help!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 108, 'total_tokens': 151, 'completion_time': 0.078181818, 'prompt_time': 0.002806145, 'queue_time': 0.249252525, 'total_time': 0.080987963}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--115c2f7c-e390-497e-ad38-d849d398d11b-0', usage_metadata={'input_tokens': 108, 'output_tokens': 43, 'total_tokens': 151})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('user', 'Hi my name is Yuvraj and Im a GenAI engineer'),\n",
    "    (\"ai\", \"Hi Yuvraj, its nice to meet you. Thats fascinating, being a GenAI engineer is cutting edge and important work. What kind of projects are you working on? Im always eager to learn more about the advancements in the field.  Perhaps you could tell me about some of the challenges and rewards you encounter in your role?\"),\n",
    "    ('user', \"Whats my name and what do i do?\")\n",
    "])\n",
    "\n",
    "chain=prompt|model\n",
    "chain.invoke({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dccd2b",
   "metadata": {},
   "source": [
    "### Message History\n",
    "We can use message history class to wrap our model and make it stateful. This will keep track of the inputs and outputs of the model and store them in some datastore. Future interactions will then load them and pass them into the chain as the input. Lets see how to use this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aed1b979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4082b47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={'configurable': {'session_id': 'chat1'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14626893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "response=with_message_history.invoke([\n",
    "    HumanMessage(content='Hi my name is Yuvraj and Im GenAI Engineer')],\n",
    "    config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4cda4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Yuvraj, it's nice to meet you! \\n\\nThat's awesome that you're a GenAI Engineer. It's a really exciting field right now. What kind of work do you do?  \\n\\nI'm always eager to learn more about how people are using AI to create new and innovative things.\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6288a4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Yuvraj and that you are a GenAI Engineer!  \\n\\nIs there anything else you'd like to tell me about yourself or your work? üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 113, 'total_tokens': 155, 'completion_time': 0.076363636, 'prompt_time': 0.002830924, 'queue_time': 0.248333846, 'total_time': 0.07919456}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--4b13adc2-83bf-419e-85d3-6920ee765c45-0', usage_metadata={'input_tokens': 113, 'output_tokens': 42, 'total_tokens': 155})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke([\n",
    "    HumanMessage(content='Hi, what is my name and what do i do?')],\n",
    "    config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30a7372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = {'configurable': {'session_id': 'chat2'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54a30a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'd be happy to use it! üòä\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 15, 'total_tokens': 55, 'completion_time': 0.072727273, 'prompt_time': 0.001247111, 'queue_time': 0.247830488, 'total_time': 0.073974384}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--a49dce85-7f23-4742-9b79-cca81d81d55b-0', usage_metadata={'input_tokens': 15, 'output_tokens': 40, 'total_tokens': 55})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changed session id using new config\n",
    "response=with_message_history.invoke([\n",
    "    HumanMessage(content='Hi what is my name?')],\n",
    "    config=config1)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cf878a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are a helpful assistant. Answer all the questions to best of your ability'),\n",
    "    MessagesPlaceholder(variable_name='messages')\n",
    "])\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55333f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Yuvraj, it's nice to meet you! \\n\\nWhat can I do for you today?  I'm ready to answer your questions and help in any way I can. üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 31, 'total_tokens': 77, 'completion_time': 0.083636364, 'prompt_time': 0.001478282, 'queue_time': 0.250632888, 'total_time': 0.085114646}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--5bba0aa7-1dc8-4f3c-8f18-fbdb18446d5d-0', usage_metadata={'input_tokens': 31, 'output_tokens': 46, 'total_tokens': 77})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'messages': [HumanMessage(content='Hi my name is Yuvraj')]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe1185b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain, get_session_history)\n",
    "config={'configurable': {'session_id': 'chat3'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38f26e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Yuvraj, it's nice to meet you! \\n\\nWhat can I do for you today?  I'm ready for any questions you have. üòÑ  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 31, 'total_tokens': 71, 'completion_time': 0.072727273, 'prompt_time': 0.001498571, 'queue_time': 0.248796638, 'total_time': 0.074225844}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--38f50641-7609-48f8-97bd-5ad63d91ed70-0', usage_metadata={'input_tokens': 31, 'output_tokens': 40, 'total_tokens': 71})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke([\n",
    "    HumanMessage(content='Hi my name is yuvraj')],\n",
    "    config=config\n",
    "    )\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e52d7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds more complexity\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are a helpful assistant. Answer all the questions to the best of your ability in {language}'),\n",
    "    MessagesPlaceholder(variable_name='messages'),\n",
    "])\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3df60c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§Ø‡•Å‡§µ‡§∞‡§æ‡§ú! \\n\\n‡§Æ‡•Å‡§ù‡•á ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§§‡•Å‡§Æ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•ã‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Æ‡•à‡§Ç ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•Ä ‡§ï‡•ã‡§à ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å?   \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 34, 'total_tokens': 76, 'completion_time': 0.076363636, 'prompt_time': 0.001475941, 'queue_time': 0.247590599, 'total_time': 0.077839577}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--a8e0cc91-aa28-49c8-952b-4f654fe84b56-0', usage_metadata={'input_tokens': 34, 'output_tokens': 42, 'total_tokens': 76})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({'messages': [HumanMessage(content='Hi My name is Yuvraj')], 'language': 'Hindi'})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b510418",
   "metadata": {},
   "source": [
    "Lets now wrap the more complicated chain in MessageHistory class. This time because there are multiple keys in the input we need to specify the correct key to use to save the chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab59998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key='messages'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32188f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§Ø‡•Å‡§µ‡§∞‡§æ‡§ú! \\n\\n‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ø‡§π‡§æ‡§Å ‡§π‡•Ç‡§Å‡•§ \\n\\n‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç? \\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={'configurable': {'session_id': 'chat4'}}\n",
    "response = with_message_history.invoke({'messages': [HumanMessage(content='Hi my name is Yuvraj')], 'language': 'Hindi'},\n",
    "                                       config=config)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b944743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
